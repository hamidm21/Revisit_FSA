{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporal and market aware embeddings\n",
    "1. load price and textual datasets\n",
    "2. prefix tweets with their time and price context\n",
    "3. fine-tune the model on text with and without the context\n",
    "4. comparing the base model with the fine-tuned masking model on the new dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification, Trainer, TrainingArguments, TrainerCallback\n",
    "from datasets import Dataset\n",
    "from torch.utils.data import DataLoader, Dataset as torchDS\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score\n",
    "from tqdm.notebook import tqdm  # Use notebook version of tqdm for better compatibility with Jupyter\n",
    "from torch.optim import AdamW\n",
    "import neptune\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "current_working_directory = os.getcwd()\n",
    "sys.path.append(os.path.dirname(current_working_directory))\n",
    "from src.util import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load price and textual datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df = pd.read_csv(\"../raw/combined_tweets_2020_labeled.csv\", usecols=[\"date\", \"text_split\"])\n",
    "text_df.rename(columns={\"text_split\": \"text\"}, inplace=True)\n",
    "text_df.set_index('date', inplace=True)\n",
    "text_df.index = pd.to_datetime(text_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_df = pd.read_csv(\"../raw/daily-2020.csv\", usecols=[\"timestamp\", \"close\", \"open\", \"high\", \"low\", \"volume\"])\n",
    "price_df.set_index('timestamp', inplace=True)\n",
    "price_df.index = pd.to_datetime(price_df.index, unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64310, 1) (366, 5)\n"
     ]
    }
   ],
   "source": [
    "print(text_df.shape, price_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prefix tweets with their time and price context\n",
    "how do we define temporal and price context in this scenario\n",
    "- temporal context: as the month and year of each tweet (e.g. Mar, 2020)\n",
    "- price context: moving average of the price, trend, percent change? No, tag the current trend based on triple barrier labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_time_string(df):\n",
    "    \"\"\"\n",
    "    Extract time string from date column to be used in the tweet\n",
    "    \"\"\"\n",
    "    df['time'] = df.index.to_series().dt.strftime('%d,%b,%Y')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prefix_text_column(df, time_col, trend_col, text_col):\n",
    "    \"\"\"\n",
    "    Prefix a text column with temporal and market context.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): The input DataFrame.\n",
    "    time_col (str): The name of the time column.\n",
    "    trend_col (str): The name of the trend column.\n",
    "    text_col (str): The name of the text column.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: The DataFrame with the prefixed text column.\n",
    "    \"\"\"\n",
    "    # Create a new column by combining the time, trend, and text columns\n",
    "    df[\"context_aware\"] = \"time: \" + df[time_col].astype(str) + \" trend: \" + df[trend_col].astype(str) + \" text: \" + df[text_col]\n",
    "\n",
    "    # Return the DataFrame\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_equal_samples(df, n_samples):\n",
    "    \"\"\"\n",
    "    Select equal numbers of tweets from each day in the dataset.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): The input DataFrame.\n",
    "    n_samples (int): The number of samples to select from each day.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: The DataFrame with the selected samples.\n",
    "    \"\"\"\n",
    "    # Get the unique dates\n",
    "    unique_dates = df.index.unique()\n",
    "\n",
    "    # Initialize an empty DataFrame to store the selected samples\n",
    "    selected_samples = pd.DataFrame()\n",
    "\n",
    "    # Iterate over each unique date\n",
    "    for date in unique_dates:\n",
    "        # Select n_samples from the current date\n",
    "        samples = df.loc[date].sample(n_samples, replace=True)\n",
    "\n",
    "        # Append the samples to the selected_samples DataFrame\n",
    "        selected_samples = pd.concat([selected_samples, samples])\n",
    "\n",
    "    # Return the selected_samples DataFrame\n",
    "    return selected_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_df = triple_barrier_labeling(price_df)\n",
    "price_df[\"text_label\"] = price_df.label.map({0: 'bearish', 1: 'neutral', 2: 'bullish'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df = extract_time_string(text_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df = text_df.merge(price_df[['label', 'text_label']], left_index=True, right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df = prefix_text_column(labeled_df, 'time', 'text_label', 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>time</th>\n",
       "      <th>label</th>\n",
       "      <th>text_label</th>\n",
       "      <th>context_aware</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-01</th>\n",
       "      <td>is the year of bitcoin bitcoin is up in decade...</td>\n",
       "      <td>01,Jan,2020</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>time: 01,Jan,2020 trend: neutral text: is the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01</th>\n",
       "      <td>activity and bases when can print they need go...</td>\n",
       "      <td>01,Jan,2020</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>time: 01,Jan,2020 trend: neutral text: activit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01</th>\n",
       "      <td>address related to his announcement why they b...</td>\n",
       "      <td>01,Jan,2020</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>time: 01,Jan,2020 trend: neutral text: address...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01</th>\n",
       "      <td>xrp btc btc price action is similar to bitcoin...</td>\n",
       "      <td>01,Jan,2020</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>time: 01,Jan,2020 trend: neutral text: xrp btc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01</th>\n",
       "      <td>about cryptocurrency and will be the beginning...</td>\n",
       "      <td>01,Jan,2020</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>time: 01,Jan,2020 trend: neutral text: about c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         text         time  \\\n",
       "2020-01-01  is the year of bitcoin bitcoin is up in decade...  01,Jan,2020   \n",
       "2020-01-01  activity and bases when can print they need go...  01,Jan,2020   \n",
       "2020-01-01  address related to his announcement why they b...  01,Jan,2020   \n",
       "2020-01-01  xrp btc btc price action is similar to bitcoin...  01,Jan,2020   \n",
       "2020-01-01  about cryptocurrency and will be the beginning...  01,Jan,2020   \n",
       "\n",
       "            label text_label  \\\n",
       "2020-01-01      1    neutral   \n",
       "2020-01-01      1    neutral   \n",
       "2020-01-01      1    neutral   \n",
       "2020-01-01      1    neutral   \n",
       "2020-01-01      1    neutral   \n",
       "\n",
       "                                                context_aware  \n",
       "2020-01-01  time: 01,Jan,2020 trend: neutral text: is the ...  \n",
       "2020-01-01  time: 01,Jan,2020 trend: neutral text: activit...  \n",
       "2020-01-01  time: 01,Jan,2020 trend: neutral text: address...  \n",
       "2020-01-01  time: 01,Jan,2020 trend: neutral text: xrp btc...  \n",
       "2020-01-01  time: 01,Jan,2020 trend: neutral text: about c...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "how_many_tweets_per_day = 2\n",
    "sampled_df = select_equal_samples(labeled_df, how_many_tweets_per_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text_label\n",
       "bullish    310\n",
       "neutral    220\n",
       "bearish    202\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_df.text_label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(sampled_df[['text', 'context_aware', 'label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.train_test_split(0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fine-tune the model on text with and without the context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_neptune_run(name, description, params):\n",
    "    \"\"\"\n",
    "    initializes and returns an instance of neptune run and sends the parameters\n",
    "    \"\"\"\n",
    "    run = neptune.init_run(\n",
    "    project=\"Financial-NLP/market-aware-embedding\",\n",
    "    api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiI2YWViODAxNC05MzNkLTRiZGMtOGI4My04M2U3MDViN2U3ODEifQ==\",\n",
    "    name=name,\n",
    "    description=description\n",
    "    )\n",
    "\n",
    "    run[\"parameters\"] = params\n",
    "    return run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(torchDS):\n",
    "    def __init__(self, hf_dataset):\n",
    "        self.hf_dataset = hf_dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.hf_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.hf_dataset[idx]\n",
    "        return {\n",
    "            'input_ids': torch.tensor(item['input_ids']),\n",
    "            'attention_mask': torch.tensor(item['attention_mask']),\n",
    "            'labels': torch.tensor(item['label'])\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    probs = softmax(pred.predictions, axis=1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    roc_auc = roc_auc_score(labels, probs, multi_class='ovr')\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'roc_auc': roc_auc\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text field in the dataset\n",
    "def tokenize_function(tokenizer, examples, text_col=\"text\"):\n",
    "    # Tokenize the text and return only the necessary fields\n",
    "    encoded = tokenizer(examples[text_col], padding='max_length', max_length=512)\n",
    "    return {\"input_ids\": encoded[\"input_ids\"], \"attention_mask\": encoded[\"attention_mask\"], \"label\": examples[\"label\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(labels, preds, probs):\n",
    "    \"\"\"\n",
    "    Compute metrics based on the model's predictions and the true labels.\n",
    "\n",
    "    Args:\n",
    "    labels (any): The true labels.\n",
    "    preds (any): The model's predictions.\n",
    "    probs (any): The model's probabilities\n",
    "\n",
    "    Returns:\n",
    "    dict: The computed metrics.\n",
    "    \"\"\"\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "\n",
    "    # Create a dictionary of metrics\n",
    "    metrics = {\n",
    "        \"accuracy\": acc,\n",
    "        \"f1\": f1,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "    }\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_dataloader, epochs, learning_rate, neptune_run=None, device=None):\n",
    "    epoch_results = {}\n",
    "\n",
    "    if device is None:\n",
    "        device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    # Move the model to the device\n",
    "    model.to(device)\n",
    "    # Set up the optimizer\n",
    "    optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in tqdm(range(epochs)):  # Number of epochs\n",
    "        all_labels = []\n",
    "        all_preds = []\n",
    "        all_probs = []  # For storing probabilities\n",
    "        for batch in tqdm(train_dataloader):\n",
    "            optimizer.zero_grad()\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Store labels, predictions and probabilities for metrics calculation\n",
    "            preds = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "            all_probs.append(preds.detach().cpu().numpy())  # Store probabilities\n",
    "            class_preds = torch.argmax(preds, dim=-1)\n",
    "            all_preds.append(class_preds.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "        # Calculate and log metrics after each epoch\n",
    "        all_labels = np.concatenate(all_labels)\n",
    "        all_preds = np.concatenate(all_preds)\n",
    "        all_probs = np.concatenate(all_probs)  # Concatenate probabilities\n",
    "        results = compute_metrics(all_labels, all_preds, all_probs)\n",
    "        if neptune_run != None:\n",
    "            neptune_run[\"train/accuracy\"].log(results[\"accuracy\"])\n",
    "            neptune_run[\"train/precision\"].log(results[\"precision\"])\n",
    "            neptune_run[\"train/recall\"].log(results[\"recall\"])\n",
    "            neptune_run[\"train/f1\"].log(results[\"f1\"])\n",
    "        epoch_results[epoch] = results\n",
    "\n",
    "    # Return both the trained model and the epoch results\n",
    "    return model, epoch_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, eval_dataloader, neptune_run=None, device=None):\n",
    "    eval_results = {}\n",
    "\n",
    "    if device is None:\n",
    "        device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    # Move the model to the device\n",
    "    model.to(device)\n",
    "\n",
    "    # Evaluation loop\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():  # Disable gradient calculation\n",
    "        all_labels = []\n",
    "        all_preds = []\n",
    "        all_probs = []  # For storing probabilities\n",
    "        for batch in tqdm(eval_dataloader):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "\n",
    "            # Store labels, predictions and probabilities for metrics calculation\n",
    "            preds = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "            all_probs.append(preds.detach().cpu().numpy())  # Store probabilities\n",
    "            class_preds = torch.argmax(preds, dim=-1)\n",
    "            all_preds.append(class_preds.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "        # Calculate and log metrics after each epoch\n",
    "        all_labels = np.concatenate(all_labels)\n",
    "        all_preds = np.concatenate(all_preds)\n",
    "        all_probs = np.concatenate(all_probs)  # Concatenate probabilities\n",
    "        results = compute_metrics(all_labels, all_preds, all_probs)\n",
    "        if neptune_run != None:\n",
    "            neptune_run[\"eval/accuracy\"].log(results[\"accuracy\"])\n",
    "            neptune_run[\"eval/precision\"].log(results[\"precision\"])\n",
    "            neptune_run[\"eval/recall\"].log(results[\"recall\"])\n",
    "            neptune_run[\"eval/f1\"].log(results[\"f1\"])\n",
    "        eval_results = results\n",
    "    return eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizing the dataset text to be used in train and test loops\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ElKulako/cryptobert\")\n",
    "partial_tokenize_function_text = partial(tokenize_function, tokenizer, text_col=\"text\")\n",
    "partial_tokenize_function_context = partial(tokenize_function, tokenizer, text_col=\"context_aware\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39c069aeaef742c69a7fc87213150d9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/585 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c089b89fa8247eab15de0afb55dd452",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/147 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02f62b28815b40ffa92c0e5d41a3807c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/585 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac1123785663475aa3fca5194be9ac2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/147 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenizing\n",
    "tokenized_train_text = dataset[\"train\"].map(partial_tokenize_function_text, batched=True)\n",
    "tokenized_test_text = dataset[\"test\"].map(partial_tokenize_function_text, batched=True)\n",
    "tokenized_train_context = dataset[\"train\"].map(partial_tokenize_function_context, batched=True)\n",
    "tokenized_test_context = dataset[\"test\"].map(partial_tokenize_function_context, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train_text_dataset = TextDataset(tokenized_train_text)\n",
    "tokenized_test_text_dataset = TextDataset(tokenized_test_text)\n",
    "tokenized_train_context_dataset = TextDataset(tokenized_train_context)\n",
    "tokenized_test_context_dataset = TextDataset(tokenized_test_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=3\n",
    "tokenized_train_text_dataloader = DataLoader(tokenized_train_text_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "tokenized_test_text_dataloader = DataLoader(tokenized_test_text_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "tokenized_train_context_dataloader = DataLoader(tokenized_train_context_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "tokenized_test_context_dataloader = DataLoader(tokenized_test_context_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-5\n",
    "epochs = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### comparing the base model with the fine-tuned masking model on the new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"epochs\": epochs,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"train_batches\": tokenized_train_text_dataloader,\n",
    "    \"test_batches\": tokenized_test_text_dataloader\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = init_neptune_run(name=\"base_text_model\", description=\"base model fine-tuned on textual data without temporal or market context\", params=params)\n",
    "text_trained_model = AutoModelForSequenceClassification.from_pretrained(\"ElKulako/cryptobert\", num_labels=3)\n",
    "text_trained_model, _ = train_model(text_trained_model, tokenized_train_text_dataloader, epochs, learning_rate, run)\n",
    "evaluate_model(text_trained_model, tokenized_test_text_dataloader, neptune_run=run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = init_neptune_run(name=\"temporal_context_model\", description=\"base model fine-tuned on textual data with temporal and market context\", params=params)\n",
    "context_trained_model = AutoModelForSequenceClassification.from_pretrained(\"ElKulako/cryptobert\", num_labels=3)\n",
    "context_trained_model, _, = train_model(context_trained_model, tokenized_train_context_dataloader, epochs, learning_rate, run)\n",
    "evaluate_model(context_trained_model, tokenized_test_context_dataloader, neptune_run=run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/Financial-NLP/market-aware-embedding/e/MAR-6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "815f54c994e5449caee38663a3a4c895",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamid/.cache/pypoetry/virtualenvs/financial-nlp-x_4k-hl4-py3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.3877551020408163,\n",
       " 'f1': 0.244994994994995,\n",
       " 'precision': 0.2588285960378984,\n",
       " 'recall': 0.3408289241622575}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run = init_neptune_run(name=\"base_model\", description=\"base model without fine-tuning\", params=params)\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(\"ElKulako/cryptobert\", num_labels=3)\n",
    "evaluate_model(base_model, tokenized_test_context_dataloader, neptune_run=run)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
