{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Analysis\n",
    "Here are the steps taken:\n",
    "1. importing packages\n",
    "2. loading the data and creating the datasets\n",
    "3. preprocessing the datasets\n",
    "4. calculating sentiment polarity using VADER\n",
    "5. merging price and sentiment data based on their intervals\n",
    "6. selecting the suitable interval for the analysis using cross-correlation\n",
    "7. selecting the suitable MA/EMA hyperparameter (assuming context improves sentiment index)\n",
    "8. storing the selected index as a dataset to be used later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import plot as plt\n",
    "import logging\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "current_working_directory = os.getcwd()\n",
    "sys.path.append(os.path.dirname(current_working_directory))\n",
    "from utils.eda import generate_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:using debug mode\n"
     ]
    }
   ],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logging.debug(\"using debug mode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading the data and creating the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataset(source: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    This function cleans the input DataFrame by:\n",
    "    - Converting 'user_followers' and 'user_friends' columns to integer type\n",
    "    - Converting 'user_verified' column to boolean type\n",
    "    - Converting 'date' column to datetime type\n",
    "    - Dropping rows with any null values\n",
    "    - Setting 'date' as the index of the DataFrame\n",
    "    It then returns the cleaned DataFrame.\n",
    "    \"\"\"\n",
    "    df = source.copy()\n",
    "    df[\"user_followers\"] = pd.to_numeric(df[\"user_followers\"], errors='coerce').astype('Int64')\n",
    "    df[\"user_friends\"] = pd.to_numeric(df[\"user_friends\"], errors='coerce').astype('Int64')\n",
    "    df[\"user_verified\"] = df[\"user_verified\"].astype(\"bool\")\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"], errors='coerce')\n",
    "    df = df.dropna().set_index(\"date\")\n",
    "    return df\n",
    "\n",
    "def handle_dataset(file_path, df=None, columns=None):\n",
    "    \"\"\"\n",
    "    This function handles the reading and writing of datasets.\n",
    "    - If a DataFrame is provided, it writes the DataFrame to a CSV file at the given file path.\n",
    "    - If no DataFrame is provided, it checks if a file exists at the given file path and reads it if it does.\n",
    "    - If no file exists, it returns None.\n",
    "    \"\"\"\n",
    "    if df is not None:\n",
    "        logging.debug(f\"Writing to csv at {file_path}\")\n",
    "        df.to_csv(file_path)\n",
    "    elif os.path.isfile(file_path):\n",
    "        logging.debug(f\"Reading dataset from {file_path}\")\n",
    "        return pd.read_csv(file_path, lineterminator='\\n', usecols=columns).set_index(\"date\")\n",
    "    return None\n",
    "\n",
    "def slice_dataframe(sdf, start_datetime, end_datetime):\n",
    "    \"\"\"\n",
    "    This function slices a DataFrame based on a given date range.\n",
    "    - It first sorts the DataFrame by 'date'.\n",
    "    - It then slices the DataFrame based on the given start and end datetime.\n",
    "    - It returns the sliced DataFrame.\n",
    "    \"\"\"\n",
    "    sorted_df = sdf.sort_values(by='date')\n",
    "    sliced_df = sorted_df.loc[start_datetime:end_datetime]\n",
    "    return sliced_df\n",
    "\n",
    "def get_dataframe(cwd, source_dataset_address, clean_dataset_address, sliced_dataset_address):\n",
    "    \"\"\"\n",
    "    This function gets a DataFrame from a given file path.\n",
    "    - It first tries to read a sliced dataset from a given file path.\n",
    "    - If no sliced dataset exists, it tries to read a clean dataset from a given file path.\n",
    "    - If no clean dataset exists, it generates a clean dataset from a source dataset.\n",
    "    - It then slices the DataFrame and writes it to a CSV file.\n",
    "    - It returns the DataFrame.\n",
    "    \"\"\"\n",
    "    dataset_directory = os.path.join(os.path.dirname(cwd), \"dataset\")\n",
    "    clean_dataset_address = os.path.join(dataset_directory, clean_dataset_address)\n",
    "    sliced_dataset_address = os.path.join(dataset_directory, sliced_dataset_address)\n",
    "    columns = ['user_followers', 'user_friends', 'user_verified', 'date', 'text']\n",
    "\n",
    "    df = handle_dataset(sliced_dataset_address, columns=columns)\n",
    "    if df is None:\n",
    "        df = handle_dataset(clean_dataset_address, columns=columns)\n",
    "        if df is None:\n",
    "            logging.debug(\"Generating clean dataset from source\")\n",
    "            df = pd.read_csv(source_dataset_address, lineterminator='\\n', usecols=columns)\n",
    "            df = clean_dataset(df)\n",
    "            handle_dataset(clean_dataset_address, df=df)\n",
    "        df = slice_dataframe(df)\n",
    "        handle_dataset(sliced_dataset_address, df=df)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:Reading dataset from /home/hamid/src/Financial_NLP/dataset/_correlation_analysis_sliced.csv\n"
     ]
    }
   ],
   "source": [
    "# Check to see if the cleaned version of dataset exists. if not, we build the dataframe from the source.\n",
    "source_dataset_address = \"../raw/bitcoin-tweets/Bitcoin_tweets.csv\"\n",
    "clean_dataset_address = \"_correlation_analysis_clean.csv\"\n",
    "sliced_dataset_address=\"_correlation_analysis_sliced.csv\"\n",
    "df = get_dataframe(current_working_directory, source_dataset_address, clean_dataset_address, sliced_dataset_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_followers</th>\n",
       "      <th>user_friends</th>\n",
       "      <th>user_verified</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-07-17 12:00:00</th>\n",
       "      <td>1534</td>\n",
       "      <td>2044</td>\n",
       "      <td>False</td>\n",
       "      <td>Baller, Jack Mallers Calls Out Brian Armstrong...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-17 12:00:00</th>\n",
       "      <td>27309</td>\n",
       "      <td>166</td>\n",
       "      <td>False</td>\n",
       "      <td>Square developing #bitcoin-focused business as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-17 12:00:00</th>\n",
       "      <td>34</td>\n",
       "      <td>19</td>\n",
       "      <td>False</td>\n",
       "      <td>#Bitcoin\\nCurrent Price:\\n$ 31397.97\\nâ‚¬ 26640....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-17 12:00:00</th>\n",
       "      <td>953</td>\n",
       "      <td>119</td>\n",
       "      <td>False</td>\n",
       "      <td>Now tell me looking straight into my eyes that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-17 12:00:00</th>\n",
       "      <td>145324</td>\n",
       "      <td>834</td>\n",
       "      <td>True</td>\n",
       "      <td>There are a number of walk-in NHS vaccination ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-29 23:59:12</th>\n",
       "      <td>73</td>\n",
       "      <td>583</td>\n",
       "      <td>False</td>\n",
       "      <td>This only has 1k views? WTF #CRYPTO #Bitcoin #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-29 23:59:14</th>\n",
       "      <td>413361</td>\n",
       "      <td>387</td>\n",
       "      <td>False</td>\n",
       "      <td>LET'S DISCUSS THE LATEST #CRYPTO NEWS!\\n\\n-- P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-29 23:59:21</th>\n",
       "      <td>60</td>\n",
       "      <td>1049</td>\n",
       "      <td>False</td>\n",
       "      <td>@fireworksdoge Address : 0x01F69047c11DD924631...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-29 23:59:28</th>\n",
       "      <td>99</td>\n",
       "      <td>206</td>\n",
       "      <td>False</td>\n",
       "      <td>@drdisrespect doc do you #bitcoin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-29 23:59:52</th>\n",
       "      <td>4074</td>\n",
       "      <td>143</td>\n",
       "      <td>False</td>\n",
       "      <td>Yâ€™all better quit playing. Youâ€™ll sub and watc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>331234 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     user_followers  user_friends  user_verified  \\\n",
       "date                                                               \n",
       "2021-07-17 12:00:00            1534          2044          False   \n",
       "2021-07-17 12:00:00           27309           166          False   \n",
       "2021-07-17 12:00:00              34            19          False   \n",
       "2021-07-17 12:00:00             953           119          False   \n",
       "2021-07-17 12:00:00          145324           834           True   \n",
       "...                             ...           ...            ...   \n",
       "2021-07-29 23:59:12              73           583          False   \n",
       "2021-07-29 23:59:14          413361           387          False   \n",
       "2021-07-29 23:59:21              60          1049          False   \n",
       "2021-07-29 23:59:28              99           206          False   \n",
       "2021-07-29 23:59:52            4074           143          False   \n",
       "\n",
       "                                                                  text  \n",
       "date                                                                    \n",
       "2021-07-17 12:00:00  Baller, Jack Mallers Calls Out Brian Armstrong...  \n",
       "2021-07-17 12:00:00  Square developing #bitcoin-focused business as...  \n",
       "2021-07-17 12:00:00  #Bitcoin\\nCurrent Price:\\n$ 31397.97\\nâ‚¬ 26640....  \n",
       "2021-07-17 12:00:00  Now tell me looking straight into my eyes that...  \n",
       "2021-07-17 12:00:00  There are a number of walk-in NHS vaccination ...  \n",
       "...                                                                ...  \n",
       "2021-07-29 23:59:12  This only has 1k views? WTF #CRYPTO #Bitcoin #...  \n",
       "2021-07-29 23:59:14  LET'S DISCUSS THE LATEST #CRYPTO NEWS!\\n\\n-- P...  \n",
       "2021-07-29 23:59:21  @fireworksdoge Address : 0x01F69047c11DD924631...  \n",
       "2021-07-29 23:59:28                  @drdisrespect doc do you #bitcoin  \n",
       "2021-07-29 23:59:52  Yâ€™all better quit playing. Youâ€™ll sub and watc...  \n",
       "\n",
       "[331234 rows x 4 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_followers     int64\n",
       "user_friends       int64\n",
       "user_verified       bool\n",
       "text              object\n",
       "dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocessing the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "- remove ads\n",
    "- extract emojies\n",
    "- change hashtags and coin names to represent unique symbol "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculating sentiment polarity using VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/hamid/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 331234/331234 [02:15<00:00, 2445.64it/s]\n"
     ]
    }
   ],
   "source": [
    "df[['negative', 'neutral', 'positive', 'compound']] = df['text'].progress_apply(lambda text: pd.Series(sia.polarity_scores(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = pd.to_datetime(df.index)\n",
    "\n",
    "# Initialize a dictionary to store the resampled DataFrames\n",
    "resampled_dfs = {}\n",
    "\n",
    "# Resample to intervals and aggregate sentiment scores\n",
    "for interval in ['5T', '15T', '30T', 'H']:\n",
    "    resampled_dfs[interval] = df.resample(interval).agg({\n",
    "        'negative': 'mean',\n",
    "        'neutral': 'mean',\n",
    "        'positive': 'mean',\n",
    "        'compound': 'mean'\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['5T', '15T', '30T', 'H'])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resampled_dfs.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merging price and sentiment data based on their intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### selecting the suitable MA/EMA hyperparameter (assuming the context improves the sentiment index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### storing the selected index as a dataset to be used later"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
